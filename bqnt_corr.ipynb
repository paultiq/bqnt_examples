{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "Import any required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bql\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "\n",
    "pio.renderers.default='plotly_mimetype+notebook'\n",
    "pio.templates[\"iqmo\"] = pio.templates[\"plotly\"]\n",
    "pio.templates[\"iqmo\"].layout.margin = dict(l=50, r=50, t=50, b=50) \n",
    "pio.templates[\"iqmo\"].layout.height = 250\n",
    "pio.templates.default = \"iqmo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bql_svc = bql.Service()\n",
    "\n",
    "quarters = 10\n",
    "index = 'SPX Index'\n",
    "\n",
    "corr_query = f\"\"\"get(sales_rev_turn)\n",
    "    for(members('{index}'))\n",
    "    with(fpo=range(-{quarters-1}Q, 0Q), fpt=Q, fill=prev)\n",
    "    preferences(addcols=all)\"\"\"\n",
    "response = bql_svc.execute(corr_query)\n",
    "spx_rev_df = bql.combined_df(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pivot & Correlation Matrix\n",
    "\n",
    "Pandas has a useful [`corr()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html) function that computes the pairwise correlation between columns in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the data to wide: one column per security\n",
    "df_pivoted = spx_rev_df.pivot_table(index='PERIOD_OFFSET', columns='ID', values='sales_rev_turn')\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = df_pivoted.corr()\n",
    "\n",
    "# Show only 5 rows / 5 columns, for blog\n",
    "display(correlation_matrix.head(5).iloc[:, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the period/period percent change of sales_rev_turn\n",
    "spx_rev_df_sorted = spx_rev_df.sort_values(by=['ID','PERIOD'])\n",
    "\n",
    "# Compute percent change\n",
    "spx_rev_df_sorted['rev_pct_chg'] = spx_rev_df_sorted.groupby(level=0)['sales_rev_turn'].pct_change()\n",
    "\n",
    "df_pivoted = spx_rev_df_sorted.pivot_table(index='PERIOD_OFFSET', columns='ID', values='rev_pct_chg')\n",
    "\n",
    "correlation_matrix = df_pivoted.corr()\n",
    "display(correlation_matrix.head(5).iloc[:, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_matrix = correlation_matrix.head(5).iloc[:, :5]\n",
    "\n",
    "px.imshow(small_matrix, text_auto=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DuckDB\n",
    "\n",
    "The following is an example using DuckDB. DuckDB is a powerful in-memory analytics engine with a *lot* of features: it's great for problems that fit within a single server. \n",
    "\n",
    "I prefer the declarative syntax of SQL and BQL query strings to the various Pythonic APIs and DataFrame libraries. SQL queries can express complex, multi-\"step\" transformations in a single operation.\n",
    "\n",
    "This is just to demonstrate **feasibility**. The Pandas example is certainly the more concise solution in this case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This conditional code is only for blogging purposes:\n",
    "# To avoid reinstalling dependencies multiple times.\n",
    "# Don't do this in real code. Load your dependencies in a Custom Env.\n",
    "\n",
    "try:\n",
    "    import duckdb\n",
    "except Exception as e:\n",
    "    print(f\"Error importing, installing and trying again str({e})\")\n",
    "    %pip install duckdb\n",
    "    import duckdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the pandas index, to make it easier to work with in duckdb.\n",
    "spx_rev_df_c = spx_rev_df.reset_index()\n",
    "\n",
    "df_corr = duckdb.sql(\"\"\"\n",
    "with q1 as \n",
    "    -- First, compute cross_correlation\n",
    "    (SELECT a.id AS id1, \n",
    "            b.id AS id2, \n",
    "            CORR(a.sales_rev_turn, b.sales_rev_turn) AS correlation\n",
    "        FROM spx_rev_df_c a\n",
    "        JOIN spx_rev_df_c b ON a.period_offset = b.period_offset\n",
    "        GROUP BY a.id, b.id\n",
    "        ORDER BY a.id, b.id\n",
    "    )\n",
    "pivot q1 on id2 using last(correlation) group by id1 order by id1\n",
    "\"\"\").df()\n",
    "\n",
    "display(df_corr.set_index(\"id1\").head(5).iloc[:, :5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
